// Sources:
// http://stackoverflow.com/questions/39783919/tensorflow-on-nvidia-tx1
// https://www.tensorflow.org/
// http://askubuntu.com/

// TENSORFLOW CONFIGURATION

// 1.JAVA
sudo add-apt-repository ppa:webupd8team/java 
sudo apt-get update
sudo apt-get install oracle-java8-installer (get java)

// 2.NEEDED PACKAGES AND SOME DEPENDENCIES
sudo apt-get install autotools-dev
sudo apt-get install autoconf
sudo apt-get install git zip unzip autoconf automake libtool curl zlib1g-dev maven swig 

// 3. PROTOBUF INSTALLATION ( INSTALL IT ON SDCARD IF ROOT IS ONLY 15 GB )
cd /media/sdcard
mkdir libs
cd libs
git clone https://github.com/google/protobuf.git
cd protobuf
# autogen.sh downloads broken gmock.zip in d5fb408d
git checkout master
./autogen.sh
git checkout d5fb408d
autoreconf -vif
./configure --prefix=/usr
make -j 4
sudo make install
cd java
sudo mvn package

// 4. BAZEL ( INSTALL IT ON SDCARD IF ROOT IS 15 ONLY GB )
git clone https://github.com/bazelbuild/bazel.git (get bazel)
cd bazel; git checkout 0.2.1;
cp /usr/bin/protoc third_party/protobuf/protoc-linux-arm32.exe
cp /media/sdcard/protobuf/java/target/protobuf-java-3.0.0-beta-2.jar third_party/protobuf/protobuf-java-3.0.0-beta-1.jar 
// In file src/main/java/com/google/devtools/build/lib/util/CPU.java line 25 
// - ARM("arm", ImmutableSet.of("arm", "armv7l"))
// + ARM("arm", ImmutableSet.of("arm", "armv7l", "aarch64"))
sudo ./compile.sh
sudo cp output/bazel /usr/local/bin

// 5. Numpy
sudo apt-get install python-numpy

// 6. Tensorflow, some files needs to be changed
cd /media/sdcard/libs
git clone -b r0.9 https://github.com/tensorflow/tensorflow.git
cd ~
wget -O config.guess 'http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess;hb=HEAD'
wget -O config.sub 'http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.sub;hb=HEAD'

sudo cp config.sub ./.cache/bazel/_bazel_root/8a20dd5781f2ff175f9e7f51bff5eadd/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260/config.sub

sudo cp config.guess ./.cache/bazel/_bazel_root/8a20dd5781f2ff175f9e7f51bff5eadd/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260/config.guess

cd /media/sdcard/tensorflow

// FILES TO CHANGE TO BUILD WITHOUT ERRORS: 

	// FILE 1: tensorflow/core/kernels/BUILD
	-985,7 +985,7 @@ tf_kernel_libraries(
		 "reduction_ops",
		 "segment_reduction_ops",
		 "sequence_ops",
	-        "sparse_matmul_op",
	+        #DC "sparse_matmul_op",
	     ],
	     deps = [
		 ":bounds_check",

	// FILE 2: tensorflow/python/BUILD
	-1110,7 +1110,7 @@ medium_kernel_test_list = glob([
	     "kernel_tests/seq2seq_test.py",
	     "kernel_tests/slice_op_test.py",
	     "kernel_tests/sparse_ops_test.py",
	-    "kernel_tests/sparse_matmul_op_test.py",
	+    #DC "kernel_tests/sparse_matmul_op_test.py",
	     "kernel_tests/sparse_tensor_dense_matmul_op_test.py",
	 ])


	// FILE 3: tensorflow/core/kernels/cwise_op_gpu_select.cu.cc
	@@ -43,8 +43,14 @@ struct BatchSelectFunctor<GPUDevice, T> {
	     const int all_but_batch = then_flat_outer_dims.dimension(1);

	 #if !defined(EIGEN_HAS_INDEX_LIST)
	-    Eigen::array<int, 2> broadcast_dims{{ 1, all_but_batch }};
	-    Eigen::Tensor<int, 2>::Dimensions reshape_dims{{ batch, 1 }};
	+    //DC Eigen::array<int, 2> broadcast_dims{{ 1, all_but_batch }};
	+    Eigen::array<int, 2> broadcast_dims;
	+    broadcast_dims[0] = 1;
	+    broadcast_dims[1] = all_but_batch;
	+    //DC Eigen::Tensor<int, 2>::Dimensions reshape_dims{{ batch, 1 }};
	+    Eigen::Tensor<int, 2>::Dimensions reshape_dims;
	+    reshape_dims[0] = batch;
	+    reshape_dims[1] = 1;
	 #else
	     Eigen::IndexList<Eigen::type2index<1>, int> broadcast_dims;


	// FILE 4: tensorflow/core/kernels/sparse_tensor_dense_matmul_op_gpu.cu.cc
	@@ -104,9 +104,17 @@ struct SparseTensorDenseMatMulFunctor<GPUDevice, T, ADJ_A, ADJ_B> {
	     int n = (ADJ_B) ? b.dimension(0) : b.dimension(1);

	 #if !defined(EIGEN_HAS_INDEX_LIST)
	-    Eigen::Tensor<int, 2>::Dimensions matrix_1_by_nnz{{ 1, nnz }};
	-    Eigen::array<int, 2> n_by_1{{ n, 1 }};
	-    Eigen::array<int, 1> reduce_on_rows{{ 0 }};
	+    //DC Eigen::Tensor<int, 2>::Dimensions matrix_1_by_nnz{{ 1, nnz }};
	+    Eigen::Tensor<int, 2>::Dimensions matrix_1_by_nnz;
	+    matrix_1_by_nnz[0] = 1;
	+    matrix_1_by_nnz[1] = nnz;
	+    //DC Eigen::array<int, 2> n_by_1{{ n, 1 }};
	+    Eigen::array<int, 2> n_by_1;
	+    n_by_1[0] = n;
	+    n_by_1[1] = 1;
	+    //DC Eigen::array<int, 1> reduce_on_rows{{ 0 }};
	+    Eigen::array<int, 1> reduce_on_rows;
	+    reduce_on_rows[0] = 0;
	 #else
	     Eigen::IndexList<Eigen::type2index<1>, int> matrix_1_by_nnz;


	// FILE 5: tensorflow/stream_executor/cuda/cuda_blas.cc
	@@ -25,6 +25,12 @@ limitations under the License.
	 #define EIGEN_HAS_CUDA_FP16
	 #endif

	+#if CUDA_VERSION >= 8000
	+#define SE_CUDA_DATA_HALF CUDA_R_16F
	+#else
	+#define SE_CUDA_DATA_HALF CUBLAS_DATA_HALF
	+#endif
	+
	 #include "tensorflow/stream_executor/cuda/cuda_blas.h"

	 #include <dlfcn.h>
	@@ -1680,10 +1686,10 @@ bool CUDABlas::DoBlasGemm(
	   return DoBlasInternal(
	       dynload::cublasSgemmEx, stream, true /* = pointer_mode_host */,
	       CUDABlasTranspose(transa), CUDABlasTranspose(transb), m, n, k, &alpha,
	-      CUDAMemory(a), CUBLAS_DATA_HALF, lda,
	-      CUDAMemory(b), CUBLAS_DATA_HALF, ldb,
	+      CUDAMemory(a), SE_CUDA_DATA_HALF, lda,
	+      CUDAMemory(b), SE_CUDA_DATA_HALF, ldb,
	       &beta,
	-      CUDAMemoryMutable(c), CUBLAS_DATA_HALF, ldc);
	+      CUDAMemoryMutable(c), SE_CUDA_DATA_HALF, ldc);
	 #else
	   LOG(ERROR) << "fp16 sgemm is not implemented in this cuBLAS version "
		      << "(need at least CUDA 7.5)";


	// FILE 6: tensorflow/stream_executor/cuda/cuda_gpu_executor.cc
	@@ -888,6 +888,9 @@ CudaContext* CUDAExecutor::cuda_context() { return context_; }
	 // For anything more complicated/prod-focused than this, you'll likely want to
	 // turn to gsys' topology modeling.
	 static int TryToReadNumaNode(const string &pci_bus_id, int device_ordinal) {
	+  // DC - make this clever later. ARM has no NUMA node, just hardoce to return 0
	+  LOG(INFO) << "ARM has no NUMA node, hardcoding to return zero";
	+  return 0;
	 #if defined(__APPLE__)
	   LOG(INFO) << "OS X does not support NUMA - returning NUMA node zero";
	   return 0;

// 7. Configure; Build; Install;
sudo ./configure

// Possible "no space left problem", make sure you have enough space
sudo bazel build --jobs 1 -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures

sudo apt-get install python-pip

sudo bazel-bin/tensorflow/tools/pip_package/build_pip_package /media/sdcard/tensorflow/tensorflow_pkg

export LC_ALL=C
sudo pip install tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl

